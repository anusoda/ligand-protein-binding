{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e991a00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#qsub -t 1:1 embeddings_test.qsub\n",
    "from miniautoml import train_binary_classifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "#import umap.umap_ as umap\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78f3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = [1081, 3503, 4268, 5271, 6229, 6253, 6434, 7210, 7442, 7487, 8655, 8750, 8960, 9289, 9303, 9764, 10307, 10620, 11169, 11206, 11451, 12579, 12675, 13118, 13382, 13801, 14502, 14595, 14787, 15420, 18122, 18779, 20605, 20773, 20887, 21020, 22903, 22904, 22908, 22914, 23571, 23981, 24168, 25730, 26020, 26410, 29327, 29511, 29968, 30107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66e8958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READINGS EMBEDDINGS\n",
      "STARTING SAMPLING\n",
      "[1081, 3503, 4268, 5271, 6229, 6253, 6434, 7210, 7442, 7487, 8655, 8750, 8960, 9289, 9303, 9764, 10307, 10620, 11169, 11206, 11451, 12579, 12675, 13118, 13382, 13801, 14502, 14595, 14787, 15420, 18122, 18779, 20605, 20773, 20887, 21020, 22903, 22904, 22908, 22914, 23571, 23981, 24168, 25730, 26020, 26410, 29327, 29511, 29968, 30107]\n",
      "[5442, 5443, 5444, 5446, 5450, 5451, 5452, 5454, 5455, 5458, 5459, 5460, 5461, 5462, 5464, 5465, 5467, 5468, 5469, 5471, 5472, 5474, 5475, 5476, 5480, 5481, 5482, 5483, 5484, 5485, 5486, 5489, 5490, 5491, 5492, 5493, 5496, 5497, 5499, 5501, 5502, 5503, 5505, 5506, 5507, 5509, 5510, 5511, 5512, 5513]\n",
      "TRAINING MODELS\n",
      "CA2, self-AUC [0.64, 0.5900000000000001, 0.55, 0.5800000000000001, 0.61]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    print(\"TESTING MODELS\")\\n    \\n    batch_size = 1024\\n    batch_predictions = []\\n    for j in range(0, len(embeddings)//batch_size+1):\\n        batch_predictions.append(mdl.predict(embeddings[batch_size*j:batch_size*(j+1)]))\\n        print(f\"{class_of_interest}: Batch {j}\")\\n    prediction = np.concatenate(batch_predictions)\\n    current_time = datetime.datetime.now()\\n    print(current_time.strftime(\"%D:%H:%M:%S\"))\\n    with open(filename, \"a\") as file:\\n        file.write(current_time.strftime(\"%D:%H:%M:%S\") + \": prediction of \" + class_of_interest + \" complete\\n\")\\n\\n    auc_score = roc_auc_score([1 if x == class_of_interest else 0 for x in bdb_classes], prediction)\\n    print(f\"Test AUC: {auc_score}\")\\n\\n    cutoff = len(embeddings) // 100 #len(bdb_class_to_indices[\"CA12\"])\\n    correct = len([x for x in sorted(range(len(bdb_classes)), key=lambda i: prediction[i])[-cutoff:] if bdb_classes[x] == class_of_interest])\\n    lift = correct*len(bdb_classes)/(cutoff*len(bdb_class_to_indices[class_of_interest]))\\n    print(f\"Lift: {lift}\")\\n\\n    newdb[class_of_interest] = prediction\\n    '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bdb = pd.read_csv(\"../BindingDB/filtered_bdb_new_subclasses_3_14_25.csv\")\n",
    "bdb = pd.read_csv(\"../BindingDB/HeavyBDB.csv\")\n",
    "bdb_smiles = bdb[\"Ligand SMILES\"].tolist()\n",
    "bdb_classes = bdb[\"Sub_Class\"].tolist()\n",
    "bdb_types = set(bdb_classes)\n",
    "bdb_class_to_indices = {x:list() for x in bdb_types}\n",
    "for i, val in enumerate(bdb_classes):\n",
    "    bdb_class_to_indices[val].append(i)\n",
    "\n",
    "with open(\"heavydiverse50.pkl\", 'rb') as file:\n",
    "    diverse50 = pickle.load(file)\n",
    "\n",
    "print(\"READINGS EMBEDDINGS\")\n",
    "#embeddings = np.load(\"../BindingDB/final_bdb_embed.npy\").tolist()\n",
    "embeddings = np.load(\"../BindingDB/heavy_bdb_embed.npy\").tolist()\n",
    "\n",
    "bdb_total = {x:0 for x in bdb_types}\n",
    "for x in bdb_classes:\n",
    "    bdb_total[x] += 1\n",
    "\n",
    "order = sorted(bdb_total.items(), key=lambda x: -x[1])\n",
    "classes_of_interest = [\"CA2\"]\n",
    "task_id = 0\n",
    "\n",
    "#newdb = pd.read_csv(\"../BindingDB/filtered_bdb_new_subclasses_3_14_25.csv\")\n",
    "newdb = pd.read_csv(\"../BindingDB/HeavyBDB.csv\")\n",
    "mdl = 0\n",
    "for class_of_interest in classes_of_interest:\n",
    "    print(\"STARTING SAMPLING\")\n",
    "    ligands_of_interest = bdb_class_to_indices[class_of_interest]\n",
    "    #ligands_other = sorted(random.sample(list(set(range(len(bdb_smiles)))-set(ligands_of_interest)), 50)) \n",
    "    ligands_other = lo\n",
    "    #ligands_of_interest = random.sample(ligands_of_interest, 100)\n",
    "    ligands_of_interest = diverse50[class_of_interest]\n",
    "    print(ligands_other)\n",
    "    print(ligands_of_interest)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in ligands_of_interest:\n",
    "        X.append(embeddings[i])\n",
    "        Y.append(1)\n",
    "    for i in ligands_other:\n",
    "        X.append(embeddings[i])\n",
    "        Y.append(0)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    print(\"TRAINING MODELS\")\n",
    "    mdl = train_binary_classifier(X, Y, n_splits=5)\n",
    "    print(f\"{class_of_interest}, self-AUC {mdl.validation_metrics['aucs']}\")\n",
    "'''\n",
    "    print(\"TESTING MODELS\")\n",
    "    \n",
    "    batch_size = 1024\n",
    "    batch_predictions = []\n",
    "    for j in range(0, len(embeddings)//batch_size+1):\n",
    "        batch_predictions.append(mdl.predict(embeddings[batch_size*j:batch_size*(j+1)]))\n",
    "        print(f\"{class_of_interest}: Batch {j}\")\n",
    "    prediction = np.concatenate(batch_predictions)\n",
    "    current_time = datetime.datetime.now()\n",
    "    print(current_time.strftime(\"%D:%H:%M:%S\"))\n",
    "    with open(filename, \"a\") as file:\n",
    "        file.write(current_time.strftime(\"%D:%H:%M:%S\") + \": prediction of \" + class_of_interest + \" complete\\n\")\n",
    "\n",
    "    auc_score = roc_auc_score([1 if x == class_of_interest else 0 for x in bdb_classes], prediction)\n",
    "    print(f\"Test AUC: {auc_score}\")\n",
    "\n",
    "    cutoff = len(embeddings) // 100 #len(bdb_class_to_indices[\"CA12\"])\n",
    "    correct = len([x for x in sorted(range(len(bdb_classes)), key=lambda i: prediction[i])[-cutoff:] if bdb_classes[x] == class_of_interest])\n",
    "    lift = correct*len(bdb_classes)/(cutoff*len(bdb_class_to_indices[class_of_interest]))\n",
    "    print(f\"Lift: {lift}\")\n",
    "\n",
    "    newdb[class_of_interest] = prediction\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4402b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dude_embeddings = np.load(\"../DUD-E/cah2/ca2_dude_embeddings.npy\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "986822d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA2: Batch 0\n",
      "CA2: Batch 1\n",
      "CA2: Batch 2\n",
      "CA2: Batch 3\n",
      "CA2: Batch 4\n",
      "CA2: Batch 5\n",
      "CA2: Batch 6\n",
      "CA2: Batch 7\n",
      "CA2: Batch 8\n",
      "CA2: Batch 9\n",
      "CA2: Batch 10\n",
      "CA2: Batch 11\n",
      "CA2: Batch 12\n",
      "CA2: Batch 13\n",
      "CA2: Batch 14\n",
      "CA2: Batch 15\n",
      "CA2: Batch 16\n",
      "CA2: Batch 17\n",
      "CA2: Batch 18\n",
      "CA2: Batch 19\n",
      "CA2: Batch 20\n",
      "CA2: Batch 21\n",
      "CA2: Batch 22\n",
      "CA2: Batch 23\n",
      "CA2: Batch 24\n",
      "CA2: Batch 25\n",
      "CA2: Batch 26\n",
      "CA2: Batch 27\n",
      "CA2: Batch 28\n",
      "CA2: Batch 29\n",
      "CA2: Batch 30\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "batch_predictions = []\n",
    "for j in range(0, len(dude_embeddings)//batch_size+1):\n",
    "    batch_predictions.append(mdl.predict(dude_embeddings[batch_size*j:batch_size*(j+1)]))\n",
    "    print(f\"{class_of_interest}: Batch {j}\")\n",
    "prediction = np.concatenate(batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3314fa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"medium_adversarial_ca2_dude_pred.npy\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c8367b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31663"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5732701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
